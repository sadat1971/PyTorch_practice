{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003_pytorch_Neural_Net.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQGq3z1CVrfTgdbQtSZ3KU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadat1971/PyTorch_practice/blob/main/003_pytorch_Neural_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ApCmQRCkMXx"
      },
      "source": [
        "# Neural Network with Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMH3UVPXkXiY"
      },
      "source": [
        "This notebook will create a convolutional neural network practice session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjNgWZpGkEkI"
      },
      "source": [
        "import torch\n",
        "from torch.nn.functional import max_pool2d, relu"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuqH5W56kP9Y",
        "outputId": "00aec6e3-d094-4dfd-85d0-3f8ac1378f0c"
      },
      "source": [
        "class convnet(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(convnet, self).__init__()\n",
        "    # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(1, 6, 3)\n",
        "    self.conv2 = torch.nn.Conv2d(6, 16, 3) # from the output of the first layer, we took 6 inputs (that were outputs of the first layer), 16 outputs and 3X3 square conv kernel\n",
        "    self.fc1 = torch.nn.Linear(16*6*6, 120) # Images are 6X6\n",
        "    self.fc2 = torch.nn.Linear(120, 84)\n",
        "    self.fc3 = torch.nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = max_pool2d(self.conv1(x), (2,2)) #max pooling over 2X2\n",
        "    x = max_pool2d(self.conv2(x), (2,2)) #max pooling over 2X2\n",
        "    x = x.view(-1, self.flattened_features(x))\n",
        "    x = relu(self.fc1(x))\n",
        "    x = relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def flattened_features(self, x):\n",
        "    size = x.size()[1:] # The first diememsion is the batch size, we just want to avoid that and have rest of the dimensions\n",
        "    flattened = 1\n",
        "    for sz in size:\n",
        "      flattened = flattened*sz\n",
        "    return flattened\n",
        "\n",
        "\n",
        "\n",
        "Convnet = convnet()\n",
        "print(Convnet)\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convnet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsDNneX7ySii"
      },
      "source": [
        "Now, let's buid a random image and feed in to out convolution net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsCN0JKCp32b",
        "outputId": "4f3fdd7e-2e0f-47c2-be46-b44c4e86ee47"
      },
      "source": [
        "image_test = torch.randn(1, 1, 32, 32)\n",
        "Out = Convnet(image_test)\n",
        "Out"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0036,  0.1115, -0.0169, -0.0016,  0.1517,  0.1368, -0.0038,  0.1104,\n",
              "          0.1421, -0.0708]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zTRmbUdrgn_"
      },
      "source": [
        "# Zero the gradient buffers of all parameters and backprops with random gradients:\n",
        "\n",
        "\n",
        "Convnet.zero_grad()\n",
        "Out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBGWK3D6z3Mc"
      },
      "source": [
        "## From the website\n",
        "* torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
        "\n",
        "* For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n",
        "\n",
        "* If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.\n",
        "\n",
        "### Before proceeding further, let’s recap all the classes you’ve seen so far.\n",
        "\n",
        "Recap:\n",
        "* torch.Tensor - A multi-dimensional array with support for autograd operations like backward(). Also holds the gradient w.r.t. the tensor.\n",
        "* nn.Module - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
        "* nn.Parameter - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a Module.\n",
        "* autograd.Function - Implements forward and backward definitions of an autograd operation. Every Tensor operation creates at least a single Function node that connects to functions that created a Tensor and encodes its history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01o5XoG-zuA6",
        "outputId": "e10076e5-2fb8-4714-b8aa-402c22edee34"
      },
      "source": [
        "# Defining the loss\n",
        "\n",
        "inp = torch.randn(1, 1, 32, 32) # make a random input\n",
        "out = Convnet(inp) # run it through your defined neural network\n",
        "Ground_truth = torch.randn(1, 10) # build a random ground truth\n",
        "Ground_truth = Ground_truth.view(1, -1) # make the GT as same shape as output\n",
        "LOSS = torch.nn.MSELoss() # make the loss instance\n",
        "loss = LOSS(out, Ground_truth)\n",
        "print(loss)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8267, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJZ8Pe2G5Upo"
      },
      "source": [
        "## Important:\n",
        "\n",
        "So, when we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requires_grad=True will have their .grad Tensor accumulated with the gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nJnmXOM0xgF",
        "outputId": "91011ef6-fb19-4fc3-a8c8-f6eb8109340e"
      },
      "source": [
        "print(loss.grad_fn) #MSE Loss\n",
        "print(loss.grad_fn.next_functions[0][0]) #Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) #RELU"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7f94d40e56a0>\n",
            "<AddmmBackward object at 0x7f94d4a10080>\n",
            "<AccumulateGrad object at 0x7f94d4a10a58>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jKk_9gO-JtA"
      },
      "source": [
        "## Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaTQ8D6k5WrV",
        "outputId": "6279afc3-91dd-4caf-e76d-500b54e9411c"
      },
      "source": [
        "# the first step of backpropagation is to zeroing the existing gradient values\n",
        "Convnet.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(Convnet.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(Convnet.conv1.bias.grad)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0028,  0.0024, -0.0189,  0.0066,  0.0020,  0.0076])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kd1Gzaw_Zc5"
      },
      "source": [
        "Great ! Now that we are done with backpropagation, we need to update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVPWBJqr-LL9"
      },
      "source": [
        "learning_rate = 0.01 #setting the learning rate \n",
        "for f in Convnet.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate) \n",
        "\n",
        "# In the convnet parameters, we have all the learnable parameters or weights. Now, by using the sub_ module, we are just subtracting the multiplication of the gradient value and learning rate.\n",
        "# weight = weight - learning_rate * gradient"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu39p69QAmHz"
      },
      "source": [
        "## Putting all the backprop and update together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oW8PQcP_gEm"
      },
      "source": [
        "#create an optimizer instance\n",
        "optim = torch.optim.SGD(Convnet.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "#The following portion will go to the training loop\n",
        "optim.zero_grad()\n",
        "output = Convnet(inp)\n",
        "loss = LOSS(output, Ground_truth)\n",
        "loss.backward()\n",
        "optim.step() #will do the update"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjf88bZWBwt0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}